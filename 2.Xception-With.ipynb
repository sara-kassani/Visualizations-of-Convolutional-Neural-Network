{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "import keras.callbacks as kcall\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train-preprocess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train-preprocess 0\n",
      "data/train-preprocess/MEL 1113\n",
      "data/train-preprocess/DF 115\n",
      "data/train-preprocess/BKL 1099\n",
      "data/train-preprocess/BCC 514\n",
      "data/train-preprocess/VASC 142\n",
      "data/train-preprocess/AKIEC 327\n",
      "data/train-preprocess/NV 6705\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(train_dir):\n",
    "    print (root, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7515 images belonging to 7 classes.\n",
      "Found 2500 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size = target_size,       \n",
    "        class_mode = 'categorical',\n",
    "        subset=\"training\",\n",
    "        shuffle = True)\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size = target_size,        \n",
    "        class_mode = 'categorical',\n",
    "        subset = \"validation\",\n",
    "        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intilizing variables\n",
    "output_classes = 7\n",
    "learning_rate = 0.001\n",
    "img_width, img_height,channel = 600, 450, 3\n",
    "batch_size = 32 \n",
    "epochs = 1\n",
    "resume_model = False\n",
    "xception_weights = 'pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:  1  Name:  xception\n",
      "Layer:  2  Name:  dense_1\n"
     ]
    }
   ],
   "source": [
    "if resume_model == False:\n",
    "    model = Sequential()\n",
    " \n",
    "    model.add(Xception(weights = xception_weights , include_top=False,pooling = 'avg'))\n",
    "\n",
    "    model.add(Dense(units=output_classes, activation='softmax'))\n",
    "\n",
    "    model.layers[0].trainable = True\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "  ## model.load_weights('xception_weights_tf_dim_ordering_tf_kernels_notop.h5', by_name=True)\n",
    "\n",
    "\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        print('Layer: ',i+1,' Name: ', layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  6/400 [..............................] - ETA: 24:40:57 - loss: 1.3639 - acc: 0.5365"
     ]
    }
   ],
   "source": [
    "## Training only the newly added layer\n",
    "if resume_model:\n",
    "    model = load_model('skin-classification-Xception2.h5')\n",
    "else: \n",
    "    history = model.fit_generator(train_generator,\n",
    "        steps_per_epoch=400,\n",
    "        epochs = epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Test Score: ', score[0])\n",
    "print ('Test Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = validation_generator.filenames\n",
    "truth = validation_generator.classes\n",
    "label = validation_generator.class_indices\n",
    "indexlabel = dict((value, key) for key, value in label.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict_generator(validation_generator, steps=validation_generator.samples/validation_generator.batch_size, verbose=1)\n",
    "predict_class = np.argmax(predicts, axis=1)\n",
    "errors = np.where(predict_class != truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(truth,predict_class)\n",
    "\n",
    "labels = []\n",
    "for k,v in indexlabel.items():\n",
    "    labels.append(v)\n",
    "    \n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, classes=labels,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and reports metrics with classification_report method\n",
    "def predict_and_report(gen, model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    gen.reset()\n",
    "    for img, label in gen:\n",
    "        #get true labels for batch and store them\n",
    "        y_true.extend([int(z[1]) for z in label])\n",
    "        #Get predictions as probabilities\n",
    "        batch_pred = model.predict_on_batch(img)\n",
    "        #turn probabilities to class labels and store\n",
    "        batch_pred = np.argmax(batch_pred, axis=1)\n",
    "        y_pred.extend(batch_pred)\n",
    "        #break loop\n",
    "        if gen.batch_index == 0:\n",
    "            break\n",
    "            \n",
    "    print('Accuracy:', accuracy_score(y_true, y_pred))\n",
    "    print('Area Under the Receiver Operating Characteristic Curve:', roc_auc_score(y_true, y_pred)) #Area under the curve\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_report(train_generator, model)\n",
    "predict_and_report(validation_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_acc = max(result.history['acc'])\n",
    "best_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_acc = result.history['acc'][-1]\n",
    "last_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append([train_dir, optimizer,learning_rate, batch_size, epochs, last_train_acc, best_train_acc, score[0], score[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas  as  pd\n",
    "res = pd.DataFrame(results)\n",
    "res.columns = ['data', 'optimizer','learning_rate','batch_size', 'epochs','last_train_accuracy', 'best_training_accuracy','test Score', 'test_accuracy']\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"Xception2-with.csv\", sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
